{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['2','1','0','1','0','2','0','2','1','1'],[1,2,3,1,\"a\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['2','1','0','1','0','2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['2', '1', '0', '1', '0', '2', '0', '2', '1', '1', 1, 2, 3, 1, 'a']"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "def dim_reduce(lists):\n",
    "    return [j for i in lists for j in i]\n",
    "a = dim_reduce(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([2, 1, 0, 1, 0, 2])"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "unique = np.unique(a)\n",
    "index_src = np.array([np.argwhere(unique==element)[0][0] for element in b])\n",
    "index_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "out = torch.zeros(index_src.size,unique.size)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[2],\n        [1],\n        [0],\n        [1],\n        [0],\n        [2]])"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "index = torch.LongTensor(index_src).view(-1,1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0., 0., 1., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0.]])"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "out.scatter_(dim=1,index=index,value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from /usr/local/lib/python3.7/site-packages/jieba/dict.txt ...\nLoading model from cache /var/folders/sl/q8x6_03132dfk7rktf00yh880000gn/T/jieba.cache\nLoading model cost 0.9591760635375977 seconds.\nPrefix dict has been built succesfully.\n网易 是 中国 领先 的 互联网 技术 公司 ， 为 用户 提供 免费邮箱 、 游戏 、 搜索引擎 服务 ， 开设 新闻 、 娱乐 、 体育 等 30 多个 内容 频道 ， 及 博客 、 视频 、 论坛 等 互动 交流 ， 网聚 人 的 力量 ,   网易 评论 不错 哦\n['30', '不错', '中国', '互动', '互联网', '交流', '体育', '免费邮箱', '公司', '内容', '力量', '博客', '多个', '娱乐', '开设', '技术', '提供', '搜索引擎', '新闻', '服务', '游戏', '用户', '网易', '网聚', '视频', '论坛', '评论', '领先', '频道']\n[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1]]\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "\n",
    "data = jieba.cut(\"网易是中国领先的互联网技术公司，为用户提供免费邮箱、游戏、搜索引擎服务，开设新闻、娱乐、体育等30多个内容频道，及博客、视频、论坛等互动交流，网聚人的力量, 网易评论不错哦\")\n",
    "# for temp in data:\n",
    "#     print(temp)\n",
    "data = ' '.join(data)\n",
    "print(data)\n",
    "vector = CountVectorizer()\n",
    "res = vector.fit_transform([data])\n",
    "print(vector.get_feature_names())\n",
    "print(res.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0. 1. 0. 0. 1. 1. 0. 0. 0.]]\n"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "# 说所有的样本加起来必须保证所有列的特征值都要遍历到\n",
    "enc.fit([['男', '中国', '足球'],\n",
    "         ['女', '美国', '篮球'],\n",
    "         ['男', '日本', '羽毛球'],\n",
    "         ['女', '中国', '乒乓球']])  # 这里一共有4个数据，3种特征\n",
    "array = enc.transform([['男', '美国', '乒乓球']]).toarray()  # 这里使用一个新的数据来测试\n",
    "print(array)  # [[ 1  0  0  1  0  0  0  0  1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot 解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['男', '美国', '乒乓球']], dtype=object)"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "enc.inverse_transform(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}