{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不能在词性标注之前删除停用词，否则语义不通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('I', 'PRP'), ('was', 'VBD'), ('watching', 'VBG'), ('TV', 'NN'), ('.', '.')]\n"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "s=\"I was watching TV.\"\n",
    "print(nltk.pos_tag(word_tokenize(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 其中\n",
    "### PRP----人称代词\n",
    "### VBD—动词的过去式\n",
    "### VBG—动词的动名词用法\n",
    "### NN—专用名词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选出名词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['TV']\n"
    }
   ],
   "source": [
    "#导入库\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "s=\"I was watching TV.\"\n",
    "#对字符串s标注\n",
    "tagged=nltk.pos_tag(word_tokenize(s))\n",
    "#输出所有词性里边的名词\n",
    "all_noun=[word for word ,pos in tagged if pos in ['NN','mnp']]\n",
    "print(all_noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram标注器是一种顺序标注器，会在其所在的上下文环境中标注出前n个单词，并预测给定词项的Pos标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "#一元模型标注，只考虑条件概率\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import DefaultTagger\n",
    "#会考虑给定单词和该单词前一个单词\n",
    "from nltk.tag import BigramTagger\n",
    "#与前面两个都有关\n",
    "from nltk.tag import TrigramTagger\n",
    "#brown训练集\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "default_tagger = nltk.DefaultTagger('NN')\n",
    "#训练集\n",
    "train_data=brown_tagged_sents[:int(len(brown_tagged_sents)*0.9)]\n",
    "test_data=brown_tagged_sents[int(len(brown_tagged_sents)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.8361407355726104\n0.8452108043456593\n0.843317053722715\n"
    }
   ],
   "source": [
    "#backoff是指当不能进行正确的标签预测时会咨询backoff\n",
    "#一元模型\n",
    "unigram_tagger=UnigramTagger(train_data,backoff=default_tagger)\n",
    "print(unigram_tagger.evaluate(test_data))\n",
    "#二元模型\n",
    "bigram_tagger=BigramTagger(train_data,backoff=unigram_tagger)\n",
    "print(bigram_tagger.evaluate(test_data))\n",
    "#三元模型\n",
    "trigram_tagger=TrigramTagger(train_data,backoff=bigram_tagger)\n",
    "print(trigram_tagger.evaluate(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['I', 'think', 'I', 'can', 'do', 'it', '?']"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "test = \"I think I can do it ?\".split(' ')\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则表达式标注器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.31306687929831556\n"
    }
   ],
   "source": [
    "#导入训练集\n",
    "from nltk.corpus import brown\n",
    "#NLTK正则标注器\n",
    "from nltk.tag.sequential import RegexpTagger\n",
    "#对词性进行标注\n",
    "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
    "#测试集\n",
    "test_data = brown_tagged_sents[int(len(brown_tagged_sents) * 0.9):]\n",
    "regexp_tagger=RegexpTagger([\n",
    "( r'^-?[0-9]+(.[0-9]+)?$', 'CD'),\n",
    "( r'(The|the|A|a|An|an)$', 'AT'),\n",
    "( r'.*able$', 'JJ'),\n",
    "( r'.*ness$', 'NN'),    #以Ness结尾大多是名词\n",
    "( r'.*ly$', 'RB'),      #以ly结尾大多是副词\n",
    "( r'.*s$', 'NNS'),      #以s结尾的大多是复数名词\n",
    "(r'.*ing$', 'VBG'),     #以ing结尾的大多是动名词\n",
    "(r'.*ed$', 'VBD'),      #以ed结尾的大多数是动词过去式\n",
    "(r'.*', 'NN')\n",
    "])\n",
    "print(regexp_tagger.evaluate(test_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.命名实体识别（NER）\n",
    "NER主要由实体名、位置和组织等。NLTK库提供了ne_chunk方法。需要先对语句进行标识化处理，然后再进行语块分解和词性标注的处理顺序，之后进行命名实体标注。\n",
    "简单看一看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(S\n  (PERSON Mark/NNP)\n  is/VBZ\n  studying/VBG\n  at/IN\n  (ORGANIZATION Stanford/NNP University/NNP)\n  in/IN\n  (GPE California/NNP))\n"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk import ne_chunk\n",
    "sent=\"Mark is studying at Stanford University in California\"\n",
    "print(ne_chunk(nltk.pos_tag(word_tokenize(sent)),binary=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}