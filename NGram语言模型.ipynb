{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadtext(path):\n",
    "    return open(path,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loadtext('/Users/manmanzhang/Library/Mobile Documents/com~apple~CloudDocs/MyProject/InferenceSystem/src/I5_algorithm/NLP数据集合/豆瓣电影数据集(2019.3)/豆瓣电影简介.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只保留中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findchinese(text):\n",
    "    return \"\".join(re.findall('[\\u4E00-\\u9FA5]',text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_word_dict(text,outputType = \"dict\"):\n",
    "\n",
    "    chinese = findchinese(text)\n",
    "\n",
    "    words = np.array(list(jieba.cut_for_search(chinese)))\n",
    "\n",
    "    unique, counts = np.unique(words, return_counts=True)\n",
    "\n",
    "    n = words.size\n",
    "    \n",
    "    if outputType == \"dict\":\n",
    "        return dict(zip(unique,counts/n))\n",
    "    elif outputType == 'array':\n",
    "        return np.c_[unique,counts/n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from /usr/local/lib/python3.7/site-packages/jieba/dict.txt ...\nLoading model from cache /var/folders/sl/q8x6_03132dfk7rktf00yh880000gn/T/jieba.cache\nLoading model cost 1.0650320053100586 seconds.\nPrefix dict has been built succesfully.\n"
    }
   ],
   "source": [
    "word_dict = creat_word_dict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([['一', '0.0008042721298864966'],\n       ['一一', '4.4752821217849576e-05'],\n       ['一一对', '5.114608139182808e-07'],\n       ...,\n       ['龟裂', '5.114608139182808e-07'],\n       ['龟鹤', '2.557304069591404e-07'],\n       ['龢', '2.557304069591404e-07']], dtype='<U34')"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "creat_word_dict(text,outputType='array')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查特征字典得到概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"经常\",\"经\",\"有\",\"有意见\",\"意见\",\"分歧\",\"见\",\"意\",\"见分歧\",\"分\"]\n",
    "prob_list = [0.1,0.05,0.1,0.1,0.2,0.2,0.05,0.05,0.05,0.1]\n",
    "word_dict = dict(zip(words,-np.log(prob_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dict(word,word_dict=word_dict):\n",
    "    return np.array(word_dict[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理查表各种情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(words):\n",
    "    if isinstance(words,str):\n",
    "        try:\n",
    "            return check_dict(words)\n",
    "        except Exception:\n",
    "            return 0\n",
    "    elif isinstance(words,(tuple,list,np.ndarray)):\n",
    "        n = len(words)\n",
    "        result = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                temp = check_dict(word)\n",
    "            except Exception:\n",
    "                temp = 0\n",
    "            result.append(temp)\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0])"
     },
     "metadata": {},
     "execution_count": 190
    }
   ],
   "source": [
    "prob(['我'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum_log_joint_prob(words,display=False):\n",
    "    P = prob(words)\n",
    "    logfile = []\n",
    "    expr = 0\n",
    "    for p in P:\n",
    "        if p == 0:\n",
    "            expr += 10**(-8)\n",
    "            if display:\n",
    "                logfile.append({\"p\":p,\"log(p)\":0,\"expr\":expr})\n",
    "        else:\n",
    "            logp = -np.log(p)\n",
    "            expr += logp\n",
    "            if display:\n",
    "                logfile.append({\"p\":p,\"log(p)\":logp,\"expr\":expr})\n",
    "    if display:\n",
    "        return expr,{''.join(words):logfile}\n",
    "    return expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2e-08,\n {'在北京': [{'p': 0, 'log(p)': 0, 'expr': 1e-08},\n   {'p': 0, 'log(p)': 0, 'expr': 2e-08}]})"
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "cum_log_joint_prob(['在','北京'],display= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(2e-08,\n {'1路': [{'p': 0, 'log(p)': 0, 'expr': 1e-08},\n   {'p': 0, 'log(p)': 0, 'expr': 2e-08}]})"
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "source": [
    "cum_log_joint_prob(['1','路'],display= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 换底公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "3.3219280948873626"
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "source": [
    "def log(a,b=2):\n",
    "    return np.log(a)/np.log(b)\n",
    "log(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 枚举词语组合可能性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm(iter):\n",
    "    return list(permutations(iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ngram(word_list,n):\n",
    "    sentence = to_numpy(word_list)\n",
    "    m = sentence.size\n",
    "    return np.array([np.array([word_list[j] for j in range(i) ][-n:]) for i in range(m+1)][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram语言模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['他', '是', '一', '个', '人'], dtype='<U1')"
     },
     "metadata": {},
     "execution_count": 196
    }
   ],
   "source": [
    "def to_numpy(data):\n",
    "    if isinstance(data,np.ndarray):\n",
    "        return data\n",
    "    else:\n",
    "        return np.array(data)\n",
    "to_numpy([\"他\",\"是\",\"一\",\"个\",\"人\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score(textList,n=2,display= False):\n",
    "    if n ==1:\n",
    "        model_name = 'Unigram'\n",
    "    elif n == 2:\n",
    "        model_name = 'Bigram'\n",
    "    elif n == 3:\n",
    "        model_name = 'Trigram'\n",
    "    else:\n",
    "        model_name = 'N-gram'\n",
    "\n",
    "    text , m ,expr  = [],len(textList),0\n",
    "    model_type = n == 1 and 'Bayesian Model' or \"Markov Model\"\n",
    "    number = 0\n",
    "\n",
    "    for arr,char in zip(Ngram(textList,n),textList):\n",
    "        arr_dim = arr.size\n",
    "        check_prob = cum_log_joint_prob(arr,display=display)\n",
    "        \n",
    "\n",
    "        if isinstance(check_prob,float):\n",
    "\n",
    "            PAB = check_prob\n",
    "        else:\n",
    "            PAB , state = check_prob\n",
    "            text.append(state)\n",
    "\n",
    "        if arr_dim == 1:\n",
    "            expr += PAB\n",
    "        elif arr_dim > 1:\n",
    "            PB = prob(char)\n",
    "            expr += PAB/(-np.log(PB))\n",
    "\n",
    "    if display:\n",
    "        return {\"{}{}{}\".format(model_type,\"->\",model_name):expr},text\n",
    "    return {\"{}{}{}\".format(model_type,\"->\",model_name):expr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Markov Model->Trigram': -inf}"
     },
     "metadata": {},
     "execution_count": 198
    }
   ],
   "source": [
    "score(\"它 是 一 个 人\".split(),3,display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Language_Model(words_list,n=2,display=False):\n",
    "    possibility = perm(words_list)\n",
    "    result = []\n",
    "    for group in possibility:\n",
    "        check = score(group,n,display=False)\n",
    "        model_name = list(check)[0]\n",
    "        score_ = check[model_name]\n",
    "        result.append(score_)\n",
    "        if display:\n",
    "            print(model_name,score_)\n",
    "    return possibility[result.index(min(result))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('经', '经常', '有', '有意见', '意见', '见', '意', '见分歧', '分', '分歧')"
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "source": [
    "Language_Model(words,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(('去', '北京', '玩', '不'), ('我', '要', '不'))"
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "source": [
    "Language_Model(('去','北京','玩','不'),2),Language_Model([\"我\",\"要\",\"不\"],n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwoard_slide(original,index_,max_len = 5):\n",
    "    return original[index_:index_+max_len]\n",
    "\n",
    "\n",
    "def forwoard_test_word(text,dict_):\n",
    "    char_len = len(text)\n",
    "    for char_index in range(char_len,0,-1):\n",
    "        temp_word = text[0:char_index]\n",
    "        if temp_word in dict_:\n",
    "            return temp_word\n",
    "\n",
    "def forwoard_max_matching(original,max_len,dictionaries):\n",
    "    result = []\n",
    "    dict_ = list(dictionaries)\n",
    "    n = len(original)\n",
    "    for i in range(n):\n",
    "        temp_text = forwoard_slide(original,i,max_len)\n",
    "        temp_word = forwoard_test_word(temp_text,dictionaries)\n",
    "        if temp_word != None:\n",
    "            result.append(temp_word)\n",
    "    return result\n",
    "\n",
    "\n",
    "def backward_slide(original,index_,max_len = 5):\n",
    "    cut = index_-max_len\n",
    "    if cut < 0:\n",
    "        cut = 0\n",
    "    return original[cut:index_]\n",
    "\n",
    "def backward_test_word(text,dict_):\n",
    "    char_len = len(text)\n",
    "    for char_index in range(char_len):\n",
    "        temp_word = text[char_index:char_index+char_len]\n",
    "        if temp_word in dict_:\n",
    "            return temp_word\n",
    "\n",
    "def backward_max_matching(original,max_len,dictionaries):\n",
    "    result = []\n",
    "    dict_ = list(dictionaries)\n",
    "    n = len(original)\n",
    "    for i in range(n-1,0,-1):\n",
    "        temp_text = backward_slide(original,i)\n",
    "        temp_word = backward_test_word(temp_text,dict_)\n",
    "        if temp_word:\n",
    "            result.append(temp_word)\n",
    "    return result[::-1]\n",
    "\n",
    "\n",
    "def MaxMatching(original,max_len,word_dict,modeltype=\"search\"):\n",
    "    set_backward , set_forwoard = set(backward_max_matching(original,max_len,word_dict)),set(forwoard_max_matching(original,max_len,word_dict))\n",
    "    filter_one = lambda SET : set(filter(lambda x : len(x) == 1,SET))\n",
    "    filter_one_plus = lambda SET : set(filter(lambda x : len(x) > 1,SET))\n",
    "    distion = lambda SET : filter_one_plus(SET) | {char for char in filter_one(SET) if char not in \"\".join(filter_one_plus(SET))}\n",
    "    if modeltype == \"search\":\n",
    "        return set_backward | set_forwoard\n",
    "    elif modeltype == 'all':\n",
    "        return {\"backward\":distion(set_backward),\"forwoard\":distion(set_forwoard)}\n",
    "    elif modeltype == \"exact\":\n",
    "        union = set_backward & set_forwoard\n",
    "        return distion(union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "({'他们', '多少', '总说', '的', '薪资', '这个', '那个'},\n ('总说', '这个', '他们', '多少', '薪资', '那个', '的'))"
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "split_words = MaxMatching(\"他们总说这个的薪资多少那个薪资多少\",2,word_dict,modeltype = \"exact\")\n",
    "split_words,Language_Model(split_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('总说', '这个', '他们', '多少', '薪资', '那个', '薪资', '多少', '的')"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "Language_Model(jieba.cut(\"他们总说这个的薪资多少那个薪资多少\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'Markov Model->Bigram': 81.47624950157825}"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "score(list(jieba.cut(\"他们总说这个的薪资多少那个薪资多少\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['他们', '总说', '这个', '的', '薪资', '多少', '那个', '薪资', '多少']"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "list(jieba.cut(\"他们总说这个的薪资多少那个薪资多少\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pycharm-66c53067",
   "display_name": "PyCharm (InferenceSystem)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}